---
title: "Case Study 2 JL"
author: "Rashmi Patel"
date: "4/2/2021"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## R Markdown

This R Markdown document is part of SMU's Master's in Data Science Program DS 6306 "Doing Data Science." Student's are given a data set and asked to make predictions using data science methods and techniques learned in the course.  For this case study we are asumming that we have been hired by a company called DDSAnalytics that specializes in talent management. The company wants to gain a competitive edge by providing its customers with accurate predictions regarding attrition (employee turnover) and monthly salary.

We will start by importing the following data for analysis:

CaseStudy2-Data.csv:

1. Later we will import the folowing data sets that will used to make our predictions for the class contest.

* CaseStudy2CompSet No Attritioin.csv
* CaseStudy2CompSet No Solary.csv


```{r}

#Load Libraries needed for analysis
library(dplyr)
library(tidyverse)
library(visdat)
library(GGally)
library(ggplot2)
library(skimr)
library(stringr)
library(corrplot)
library(ggplot2) 
library(ggthemes)
library(vcd)
library(rpart.plot)
library(BBmisc)
```
Load Theme for plots

```{r}
#~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
#                    Set Theme for Plots
#~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
theme_set(theme_fivethirtyeight())
theme_update(axis.title = element_text()) #the default for fivethirtyeight is to not show axis labels, this removes that default so we can choose to specify and display axis titles
theme_update(plot.title = element_text(hjust = 0.5)) # changing default to center all titles

```
#~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
#                   Data Preparation
#~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
```{r}


df <- read.csv("https://raw.githubusercontent.com/JosephLazarus/CaseStudy2DDS_Work_Place_Attrition/main/the_data_folder/CaseStudy2-data.csv")

head(df)
# attach df to read variavles locally
attach(df)

#explore data structure 

str(df)

dim(df) #870 X 36

which(is.na(df)) # no NA's I don't believe it

colSums(is.na(df)) # still no NA's I believe it now

# 870 obs x 36 variables
# no NA's

summary(df)
library(skimr)
skim(df) #over18  Employeecount Standardhours have no variation

library(dplyr)
#removing these variables from the data set
df <- select(df, -c(Over18, EmployeeCount, StandardHours, EmployeeNumber))

#convert char variables to factors
var_facs <- c("Attrition","EducationField","MaritalStatus","BusinessTravel","JobRole", "Department", "OverTime", "Gender")
df[,var_facs] <- lapply(df[,var_facs] , factor, ordered = FALSE)

#convert those factors to (i) integers for later
df$iJobRole <- as.integer(df$JobRole)
df$iDepartment <- as.integer(df$Department)
df$iMaritalStatus <- as.integer(df$MaritalStatus)
df$iBusinessTravel <- as.integer(df$BusinessTravel)
df$iEducation <- as.integer(df$Education)
df$iAttrition <- as.integer(df$Attrition)

#quick check of our data
str(df)

```
#~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
#                   Exploratoration into Data
#~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

```{r}

#Look at Age
quantile(Age)
tapply(Age, Attrition, mean)
#NumCompaniesWorked
quantile(NumCompaniesWorked)
tapply(NumCompaniesWorked, Attrition, mean)
#percent SalaryHike
quantile(PercentSalaryHike)
tapply(PercentSalaryHike, Attrition, mean)
#total Working Years
quantile(TotalWorkingYears)
tapply(TotalWorkingYears, Attrition, mean)

#Monthly Income
quantile(MonthlyIncome)
tapply(MonthlyIncome, Attrition, mean)

#YearsInCurrentRole
quantile(YearsInCurrentRole)
tapply(YearsInCurrentRole, Attrition, mean)

#years with Manager
quantile(YearsWithCurrManager)
tapply(YearsWithCurrManager, Attrition, mean)

library(ggplot2)
#observed a concentration in younger employees Lets plot this
df %>% ggplot(aes(x = Age)) + geom_histogram(aes(fill = Attrition), bins = 50) + ggtitle("Histogram of Age Distribion")

#Monthlyincome could be important too, High paid employees may not want to leave
df %>% ggplot(aes(x=MonthlyIncome)) + geom_histogram(aes(fill=Attrition))

#If the employee worked at many companies past performance might predict future outcomes
df %>% ggplot(aes (x= NumCompaniesWorked)) + geom_boxplot(aes(fill = Attrition)) + ggtitle("Box Plot of Attrition and number of companies worked at")

df %>% ggplot(aes(x=Attrition, Gender)) + geom_jitter() + ggtitle("Comparing Attrition by Gender")

df %>% ggplot(aes (x= Age)) + geom_boxplot(aes(fill = Attrition)) +ggtitle("Box plot Comparing Age and Atrrition")


#I'd like to create groups by factors that we created earlier based off what we saw in the graph and the quantiles that i found important. That might help models make predictions.

# We know mean age for attrition to be  is
# No      Yes 
# 37.412 33.785 

#create Factors for age group 

df <- mutate(df, Age.Group = as.factor(case_when(Age <= 22 ~ 'Undergrad',
                                   Age <= 34 ~'Young-Professional',
                                   Age <= 44 ~ 'Veteran',
                                   Age >= 45 ~ 'Senior')))
#use quantiles to pick income brackets
quantile(MonthlyIncome)

df <- mutate(df, MonthlyIncome.Group = as.factor(case_when(MonthlyIncome <= 2800 ~ 'Low',
                                     MonthlyIncome <=4999 ~ 'Avg', 
                                     MonthlyIncome <=7999 ~ 'Above.Avg',
                                     MonthlyIncome >=8000 ~ 'High')))

quantile(YearsInCurrentRole)
tapply(YearsInCurrentRole, Attrition, mean)

df <- mutate(df, YearsWithCurrManager.Group = as.factor(case_when(YearsWithCurrManager <= 2 ~ "Lessthan2",
                                          YearsWithCurrManager <= 4 ~ "2thru4",
                                          YearsWithCurrManager <= 6.9 ~ "4thru6",
                                          YearsWithCurrManager >= 7~ "7&above")))

quantile(YearsInCurrentRole)
tapply(YearsInCurrentRole, Attrition, mean)

df <-  mutate(df, YearsInCurrentRole.Group = as.factor(case_when(YearsInCurrentRole <=2 ~ "Lessthan2", 
                                          YearsInCurrentRole <= 3 ~ "Lessthan3",
                                          YearsInCurrentRole <= 4 ~ "Lessthan4",
                                          YearsInCurrentRole >4 ~ "5&above")))


quantile(YearsAtCompany)
tapply(YearsAtCompany, Attrition,mean)

df <- mutate(df, YearsAtCompany.Group = as.factor(case_when(YearsAtCompany <= 3 ~ "LessThan3",
                                            YearsAtCompany <= 5 ~"3thru5",
                                            YearsAtCompany <= 10 ~"5thru10",
                                            YearsAtCompany > 10 ~"10&above")))



#chceck for gaps
which(is.na(df))
str(df)
length(df)

#since number of companies worked at prior lets explore further create New variable of time spent in previous jobs subtratct total work years from years at company divide by number of companies worked for
df$time.at.past.job <- ifelse(df$NumCompaniesWorked!=0, df$TotalWorkingYears-df$YearsAtCompany/df$NumCompaniesWorked,0)

library(BBmisc)
#found this column to not enhance the models unitil i normalized it
df$ntime.at.past.job <- normalize(df$time.at.past.job, method = "standardize", margin = 1L, on.constant ="quiet" )
         #df$ntime.at.past.job

```


#~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
#             Prepare data for Modeling  Train Test SPlit
#~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~


```{r}
detach("package:BBmisc")

#notice I've made attrition the first column. That makes it easy to pull out for our train/test/splits when modeling. ID isn't in here but will add it back at the end for our validation / competition.

#getting : object 'MonthlyIncome' not found add in monthly income
#did not find it to be helpful in the knn analysis
# taking these out for fun   2/171625

#dat <- select(df, c(3,2,5,7,8,10, 12, 13, 14, 16, 18, 20, 21, 22, 23, 24, 25, 26, 27, 29, 30, 31, 44, 39, 40, 43))
library(dplyr)
#dat <- select(df, c("Attrition", "Age", "Department", "EnvironmentSatisfaction", "NumCompaniesWorked", "JobInvolvement","JobLevel", "JobSatisfaction", "iMaritalStatus","MonthlyIncome", "OverTime","StockOptionLevel", "TotalWorkingYears", "YearsAtCompany", "YearsInCurrentRole", "YearsWithCurrManager" ,"YearsInCurrentRole.Group", "YearsAtCompany.Group", "MonthlyIncome"))

dat <- select(df,c("Attrition","Age.Group", "DistanceFromHome", "MonthlyIncome.Group", "TotalWorkingYears", "OverTime", "YearsAtCompany", "StockOptionLevel", "JobRole", "JobLevel", "JobInvolvement", "Education", "EnvironmentSatisfaction", "WorkLifeBalance", "YearsInCurrentRole", "YearsAtCompany.Group",  "YearsInCurrentRole", "YearsWithCurrManager"))


set.seed(43) # was 31 chainging to another prime

sample_size = round(nrow(dat)*.70) # setting what is 70%
index <- sample(seq_len(nrow(dat)), size = sample_size)

training <- dat[index, ]
test <- dat[-index, ]

dim(dat)
dim(training)
dim(test)

str(training)
detach("package:dplyr") 
detach("package:stringr")
detach("package:tidyverse")

```
#~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
#                    find important Variables
#~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~


```{r}
#This was an interative step between modeling data preparation and EDA as well.

library(pROC)
library(caret)

roc_imp <- filterVarImp(x = training[-1], y = training$Attrition)
head(roc_imp)
roc_imp

sort(roc_imp$Yes, decreasing = TRUE)

```

#~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
#                            Begin Modeling
#~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

#~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
#                         1. Support Vector Model
#~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
```{r}
set.seed(31)
SVMModel <- train(Attrition~., training , method = 'svmRadial',trControl = trainControl(method = 'repeatedcv',number = 3))
#Predict
SVM.pred <- predict(SVMModel,test)
#Print confusion matrix
SVM.CM <- confusionMatrix(SVM.pred, test$Attrition)
SVM.CM


```
#~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
#                     2. Model Decesion Tree
#~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~


```{r, Decesion Tree Model}

set.seed(31) # I like to use prime numbers as seeds. IDK why. Just like 'em

library(rpart.plot)

DTModel <-rpart(formula = Attrition ~., data = training, method = 'class')
rpart.plot(DTModel, type = 3, clip.right.labs = FALSE, branch = .3, under = TRUE )
rpart.rules(DTModel, style = "tall")


rpart.plot(DTModel)

DTModel_pred = predict(DTModel, newdata = test[-1], type = 'class')
# confusion matrix
DTM.CM <- confusionMatrix(DTModel_pred, as.factor(test$Attrition))
#notice I'm saving my confusion matrixes as an object with a standard name this will be important for us to compare our models at the end
DTM.CM

```


#~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
#                       3. KNN Model 
#~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

```{r, K Nearest Neighbors}



set.seed(31) #get that prime number ready

#Fit the model on train data
KnnModel <- train(Attrition~.,training, method = 'knn')
    #trControl = trainControl(method = 'repeatedcv', number = 3))

#Predict with test set
Knn.pred <- predict(KnnModel, test[-1])
#Print confusion matrix
Knn.CM <- confusionMatrix(Knn.pred, as.factor(test$Attrition))
Knn.CM

```
#~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
#                             Hyper Parameter tunning
#~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~


```{r, Hyper Parameter Tuning}
#using the class package to have more control
  
library(class)
library(caret)
library(dplyr)

dat2 <- select(df, c("Attrition", "Age",'NumCompaniesWorked', 'ntime.at.past.job',  'DistanceFromHome', 'EnvironmentSatisfaction', 'JobInvolvement',  'JobSatisfaction', 'OverTime', 'RelationshipSatisfaction', 'StockOptionLevel',  'TotalWorkingYears','TrainingTimesLastYear', 'WorkLifeBalance',  'YearsInCurrentRole', 'YearsSinceLastPromotion', 'YearsWithCurrManager', 'iJobRole', 'iDepartment', "iMaritalStatus"))


dat2$OverTime <- as.numeric(dat2$OverTime)


detach("package:dplyr")

set.seed(443) # big prime no wammies
iterations = 20
numks = 20
splitPerc = .70

masterAcc = matrix(nrow = iterations, ncol = numks)
masterSens = matrix(nrow = iterations, ncol = numks)
masterSpec = matrix(nrow = iterations, ncol = numks)

for(j in 1:iterations)
{
  trainIndices2 <- sample(1:dim(dat2)[1],round(splitPerc * dim(dat2)[1]))
  train.k2 <- dat2[trainIndices2,]
  test.k2 <- dat2[-trainIndices2,]
  
  for(i in 1:numks)
  {
    classifications = knn(train.k2[,2:20],test.k2[,2:20],train.k2$Attrition ,k=i,prob = TRUE)
    table(test.k2$Attrition ,classifications)
    CM = confusionMatrix(table(classifications, test.k2$Attrition))
    masterAcc[j,i] = CM$overall[1]
    masterSens[j,i] = mean(CM$byClass['Sensitivity'])
    masterSpec[j,i] = mean(CM$byClass['Specificity'] )
  }
  
}

MeanAcc = colMeans(masterAcc)
MeanSens = colMeans(masterSens)
MeanSpec = colMeans(masterSpec)

par(mfrow=c(1,1))
plot(seq(1,numks,1),MeanAcc, type = "l",xlab="k",ylab="Mean Accuracy",main="Optimal k for max Accuracy sd 7 dat norm time",sub="NA values omitted")
plot(seq(1,numks,1), MeanSens, type = "l" ,main="Sensitivity seed 7 dat norm time")
plot(seq(1,numks,1), MeanSpec, type = "l", main = "Specificty seed 7 dat norm time")

which.max(MeanAcc)
max(MeanAcc)
which.max(MeanSens)
max(MeanSens)
which.max(MeanSpec)
max(na.omit(MeanSpec)) #best avg sensitivity i could produce us 0.658

set.seed(29)


classifications = knn(train.k2[,2:20], test.k2[,2:20], train.k2$Attrition,
                      k=5, prob = TRUE)
table(test.k2$Attrition, classifications)
KNN.CM = confusionMatrix(table(test.k2$Attrition, classifications))
KNN.CM

#confusion Matrix Graph Function
draw_confusion_matrix <- function(cm,Class1,Class2) {
  
  layout(matrix(c(1,1,2)))
  par(mar=c(2,2,2,2))
  plot(c(100, 345), c(300, 450), type = "n", xlab="", ylab="", xaxt='n', yaxt='n')
  title('KNN CONFUSION MATRIX', cex.main=2)
  
  # create the matrix 
  rect(150, 430, 240, 370, col='#3F97D0')
  text(195, 435, Class1, cex=1.2)
  rect(250, 430, 340, 370, col='#F7AD50')
  text(295, 435, Class2, cex=1.2)
  text(125, 370, 'Predicted', cex=1.3, srt=90, font=2)
  text(245, 450, 'Actual', cex=1.3, font=2)
  rect(150, 305, 240, 365, col='#F7AD50')
  rect(250, 305, 340, 365, col='#3F97D0')
  text(140, 400, Class1, cex=1.2, srt=90)
  text(140, 335, Class2, cex=1.2, srt=90)
  
  # add in the cm results 
  res <- as.numeric(cm$table)
  text(195, 400, res[1], cex=1.6, font=2, col='white')
  text(195, 335, res[2], cex=1.6, font=2, col='white')
  text(295, 400, res[3], cex=1.6, font=2, col='white')
  text(295, 335, res[4], cex=1.6, font=2, col='white')
  
  # add in the specifics 
  plot(c(100, 0), c(100, 0), type = "n", xlab="", ylab="", main = "DETAILS", xaxt='n', yaxt='n')
  text(10, 85, names(cm$byClass[1]), cex=1.2, font=2)
  text(10, 70, round(as.numeric(cm$byClass[1]), 3), cex=1.2)
  text(30, 85, names(cm$byClass[2]), cex=1.2, font=2)
  text(30, 70, round(as.numeric(cm$byClass[2]), 3), cex=1.2)
  text(50, 85, names(cm$byClass[5]), cex=1.2, font=2)
  text(50, 70, round(as.numeric(cm$byClass[5]), 3), cex=1.2)
  text(70, 85, names(cm$byClass[6]), cex=1.2, font=2)
  text(70, 70, round(as.numeric(cm$byClass[6]), 3), cex=1.2)
  text(90, 85, names(cm$byClass[7]), cex=1.2, font=2)
  text(90, 70, round(as.numeric(cm$byClass[7]), 3), cex=1.2)
  
  # add in the accuracy information 
  text(30, 35, names(cm$overall[1]), cex=1.5, font=2)
  text(30, 20, round(as.numeric(cm$overall[1]), 3), cex=1.4)
  text(70, 35, names(cm$overall[2]), cex=1.5, font=2)
  text(70, 20, round(as.numeric(cm$overall[2]), 3), cex=1.4)
}  


draw_confusion_matrix(KNN.CM,"Attrition No","Attrition Yes")


```






#~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
#                         4. GLM
#~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~



```{r, General Linear Regression Model}
set.seed(31)


GLMModel <- train(Attrition~., training, method = 'glm', family=binomial, trControl = trainControl(method = 'repeatedcv',number = 5))

#predict on Test Set
GLM.Pred <- predict(GLMModel, newdata =  test[-1])

#printing Confusion Matrix
GLM.CM <- confusionMatrix(GLM.Pred, test$Attrition)
GLM.CM

#this model never worked out But it was interesting to play around with.
#drop.model <- train(Attrition~., training, method = 'mlpKerasDropoutCost')

#predict on Test Set
#drop.Pred <- predict(drop.model, newdata =  test[-1])

#drop.CM <- confusionMatrix(boost.Pred, test$Attrition)
#drop.CM

```

#~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
#                   5. Naive Bayes
#~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~



```{r, NB}

detach("package:caret")
detach("package:class")
set.seed(31)
library(e1071)
library(dplyr)
dat <- select(df, c("Attrition", "Age.Group", "DistanceFromHome", "MonthlyIncome.Group", "TotalWorkingYears", "OverTime", "YearsAtCompany", "StockOptionLevel", "JobRole", "JobLevel", "JobInvolvement", "Education", "NumCompaniesWorked", "EnvironmentSatisfaction", "WorkLifeBalance", "YearsInCurrentRole", "YearsAtCompany.Group",  "YearsInCurrentRole", "YearsWithCurrManager"))

#dat <- select(df, c("Attrition", "Age", "NumCompaniesWorked", "ntime.at.past.job", "JobInvolvement","JobLevel", "JobSatisfaction", "iMaritalStatus","MonthlyIncome", "OverTime","StockOptionLevel", "TotalWorkingYears", "YearsAtCompany", "YearsInCurrentRole", "YearsWithCurrManager" ,"YearsInCurrentRole.Group", "YearsAtCompany.Group", "MonthlyIncome.Group"))

#dat <- select(df, c("Attrition", "MonthlyIncome", "TotalWorkingYears", "OverTime", "YearsAtCompany", "StockOptionLevel", "JobLevel", "JobInvolvement", "Education", "EnvironmentSatisfaction", "NumCompaniesWorked", "DistanceFromHome", "YearsInCurrentRole", "YearsAtCompany.Group",  "YearsInCurrentRole.Group", "YearsWithCurrManager.Group", "MonthlyIncome.Group", "Age.Group"))

sample_size = round(nrow(dat)*.70) # setting what is 70%
index <- sample(seq_len(nrow(dat)), size = sample_size)

training <- dat[index, ]
test <- dat[-index, ]

#Fit the model on train data
NBModel <- naiveBayes(Attrition ~., data=training, laplace = -1)

#Validate on test set
NBM_pred <- predict(NBModel, newdata =test[-1])

library(caret)
#Print confusion matrix
NBM.CM<-confusionMatrix(NBM_pred, as.factor(test$Attrition))
NBM.CM

roc_imp <- filterVarImp(x = training[-1], y = training$Attrition, scale = FALSE)
head(roc_imp)
roc_imp

draw_confusion_matrix <- function(cm,Class1,Class2) {
  
  layout(matrix(c(1,1,2)))
  par(mar=c(2,2,2,2))
  plot(c(100, 345), c(300, 450), type = "n", xlab="", ylab="", xaxt='n', yaxt='n')
  title('N.B. CONFUSION MATRIX', cex.main=2)
  
  # create the matrix 
  rect(150, 430, 240, 370, col='#3F97D0')
  text(195, 435, Class1, cex=1.2)
  rect(250, 430, 340, 370, col='#F7AD50')
  text(295, 435, Class2, cex=1.2)
  text(125, 370, 'Predicted', cex=1.3, srt=90, font=2)
  text(245, 450, 'Actual', cex=1.3, font=2)
  rect(150, 305, 240, 365, col='#F7AD50')
  rect(250, 305, 340, 365, col='#3F97D0')
  text(140, 400, Class1, cex=1.2, srt=90)
  text(140, 335, Class2, cex=1.2, srt=90)
  
  # add in the cm results 
  res <- as.numeric(cm$table)
  text(195, 400, res[1], cex=1.6, font=2, col='white')
  text(195, 335, res[2], cex=1.6, font=2, col='white')
  text(295, 400, res[3], cex=1.6, font=2, col='white')
  text(295, 335, res[4], cex=1.6, font=2, col='white')
  
  # add in the specifics 
  plot(c(100, 0), c(100, 0), type = "n", xlab="", ylab="", main = "DETAILS", xaxt='n', yaxt='n')
  text(10, 85, names(cm$byClass[1]), cex=1.2, font=2)
  text(10, 70, round(as.numeric(cm$byClass[1]), 3), cex=1.2)
  text(30, 85, names(cm$byClass[2]), cex=1.2, font=2)
  text(30, 70, round(as.numeric(cm$byClass[2]), 3), cex=1.2)
  text(50, 85, names(cm$byClass[5]), cex=1.2, font=2)
  text(50, 70, round(as.numeric(cm$byClass[5]), 3), cex=1.2)
  text(70, 85, names(cm$byClass[6]), cex=1.2, font=2)
  text(70, 70, round(as.numeric(cm$byClass[6]), 3), cex=1.2)
  text(90, 85, names(cm$byClass[7]), cex=1.2, font=2)
  text(90, 70, round(as.numeric(cm$byClass[7]), 3), cex=1.2)
  
  # add in the accuracy information 
  text(30, 35, names(cm$overall[1]), cex=1.5, font=2)
  text(30, 20, round(as.numeric(cm$overall[1]), 3), cex=1.4)
  text(70, 35, names(cm$overall[2]), cex=1.5, font=2)
  text(70, 20, round(as.numeric(cm$overall[2]), 3), cex=1.4)
}  


draw_confusion_matrix(NBM.CM,"Attrition No","Attrition Yes")


```

#~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
#                     5. Random Forest
#~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~


```{r, RF}

detach("package:e1071")
#caret and randomForest packages don't place nice together
library(randomForest)
#fitting random forest classification to the training set
RFModel = randomForest(Attrition ~.,data = training, ntree = 50, nodesize = 1, importance = TRUE)
#Plot the prediction
plot(RFModel)
RFModel
#predicting on the test set 
RF.pred = predict(RFModel,newdata = test[-1],type="response")

#Making the confucion matrix
RFM.CM<-confusionMatrix(RF.pred, test$Attrition)
RFM.CM

detach("package:randomForest")  

```


#~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
#                   Explorator Analysis on the Models
#~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~


```{r, Model EDA}


library(ggplot2)
library(dplyr)


Sensitivities <- c(DTM.CM$byClass["Sensitivity"], GLM.CM$byClass["Sensitivity"], 
                   NBM.CM$byClass["Sensitivity"], KNN.CM$byClass["Sensitivity"], 
                   RFM.CM$byClass["Sensitivity"], SVM.CM$byClass["Sensitivity"])

Specificities <- c(DTM.CM$byClass["Specificity"], GLM.CM$byClass["Specificity"], 
                   NBM.CM$byClass["Specificity"], KNN.CM$byClass["Specificity"], 
                   RFM.CM$byClass["Specificity"], SVM.CM$byClass["Specificity"])

Precisions <- c(DTM.CM$byClass["Precision"], GLM.CM$byClass["Precision"], 
                NBM.CM$byClass["Precision"], KNN.CM$byClass["Precision"],
                RFM.CM$byClass["Percision"], SVM.CM$byClass["Percision"])

Recalls <- c(DTM.CM$byClass["Recall"], GLM.CM$byClass["Recall"], 
             NBM.CM$byClass["Recall"], KNN.CM$byClass["Recall"], RFM.CM$byClass["Recall"], SVM.CM$byClass["Recall"])

Accuracies <- c(DTM.CM$overall[1], GLM.CM$overall[1], NBM.CM$overall[1], KNN.CM$overall[1], RFM.CM$overall[1], SVM.CM$overall[1] )

Balanced_Accuracies <- c(DTM.CM$byClass["BalancedAccuracy"], GLM.CM$byClass["Balanced Accuracy"], NBM.CM$byClass["Balanced Accuracy"], KNN.CM$byClass["Balanced Accuracy"], RFM.CM$byClass["Balanced Accuracy"],  SVM.CM$byClass["Balanced Accuracy"])

F1_Scores <- c(DTM.CM$byClass["F1"], GLM.CM$byClass["F1"], NBM.CM$byClass["F1"], KNN.CM$byClass["F1"], RFM.CM$byClass["F1"], SVM.CM$byClass["F1"])

#Create a data frame from the metrics in confusion matrixes and models
Models  <- c("DTM", "GLM", "NBM", "KNN", "RFM", "SVM")
casestudy.results <- data.frame(Models, Sensitivities, Specificities, Precisions, Recalls, F1_Scores, Accuracies, Balanced_Accuracies)

casestudy.results

casestudy.results$Sensitivities <- round(casestudy.results$Sensitivities,digits = 3)
casestudy.results$Specificities <- round(casestudy.results$Specificities, digits =3)
casestudy.results$Precisions <- round(casestudy.results$Precisions, digits  = 3)
casestudy.results$Recalls <- round(casestudy.results$Recalls, digits = 3)
casestudy.results$F1_Scores <- round(casestudy.results$F1_Scores, digits=3)
casestudy.results$Accuracies <- round(casestudy.results$Accuracies, digits= 3)
casestudy.results$Balanced_Accuracies <- round(casestudy.results$Balanced_Accuracies, digits  = 3)


sn.p <-casestudy.results %>% ggplot(aes(Models, Sensitivities, fill = Models)) + geom_bar(stat='identity', alpha = 0.5) + 
  geom_text(aes(label=Sensitivities),vjust=3, size = 4) + ggtitle('Comparative Sensitivities') + xlab('') + ylab('')

sp.p <-casestudy.results %>% ggplot(aes(Models, Specificities, fill = Models)) + geom_bar(stat='identity', alpha = 0.5) + 
  geom_text(aes(label=Specificities),vjust=3, size = 4) + ggtitle('Comparative Specificities') + xlab('') + ylab('')

pr.p <-casestudy.results %>% ggplot(aes(Models, Precisions, fill = Models)) + geom_bar(stat='identity', alpha = 0.5) + 
  geom_text(aes(label=Precisions),vjust=3, size = 4) + ggtitle('Comparative Precisions') + xlab('') + ylab('')

ba.p <- casestudy.results %>% ggplot(aes(Models, Balanced_Accuracies, fill = Models)) + geom_bar(stat='identity', alpha = 0.5) + 
  geom_text(aes(label=Balanced_Accuracies),vjust=3, size = 4) + ggtitle('Comparative Balanced Accuracies') + xlab('') + ylab('')

f1.p <- casestudy.results %>% ggplot(aes(Models, F1_Scores, fill = Models)) + geom_bar(stat='identity', alpha = 0.5) + 
  geom_text(aes(label=F1_Scores),vjust=3, size = 4) + ggtitle('Comparative F1 Scores') + xlab('') + ylab('')

 
sn.p
sp.p
pr.p
ba.p
f1.p

```



#~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
#                Begin Attrition Competition 
#~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~



```{r, Attrition Competition}

#read in the competition Data set
attritionCompSet <-read.csv("https://raw.githubusercontent.com/JosephLazarus/CaseStudy2DDS_Work_Place_Attrition/main/the_data_folder/CaseStudy2CompSet%20No%20Attrition.csv")


head(attritionCompSet)
# attach attritionCompSet to read variavles locally
attach(attritionCompSet)

#explore data structure 

str(attritionCompSet)

dim(attritionCompSet) #870 X 36

which(is.na(attritionCompSet)) # make sure no funny business is going on with the comp set

library(dplyr)
#removing these variables from the data set
attritionCompSet <- select(attritionCompSet, -c(Over18, EmployeeCount, StandardHours, EmployeeNumber))

#convert char variables to factors
var_facs <- c("EducationField","MaritalStatus","BusinessTravel","JobRole", "Department", "OverTime", "Gender")
attritionCompSet[,var_facs] <- lapply(attritionCompSet[,var_facs] , factor, ordered = FALSE)

#convert those factors to (i) integers for later
attritionCompSet$iJobRole <- as.integer(attritionCompSet$JobRole)
attritionCompSet$iDepartment <- as.integer(attritionCompSet$Department)
attritionCompSet$iMaritalStatus <- as.integer(attritionCompSet$MaritalStatus)
attritionCompSet$iBusinessTravel <- as.integer(attritionCompSet$BusinessTravel)
attritionCompSet$iEducation <- as.integer(attritionCompSet$Education)


#quick check of our data
str(attritionCompSet)

attritionCompSet <- mutate(attritionCompSet, Age.Group = as.factor(case_when(Age <= 22 ~ 'Undergrad',
                                                 Age <= 34 ~'Young-Professional',
                                                 Age <= 44 ~ 'Veteran',
                                                 Age >= 45 ~ 'Senior')))


attritionCompSet <- mutate(attritionCompSet, MonthlyIncome.Group = as.factor(case_when(MonthlyIncome <= 2800 ~ 'Low',
                                                           MonthlyIncome <=4999 ~ 'Avg', 
                                                           MonthlyIncome <=7999 ~ 'Above.Avg',
                                                           MonthlyIncome >=8000 ~ 'High')))



attritionCompSet <- mutate(attritionCompSet, YearsWithCurrManager.Group = as.factor(case_when(YearsWithCurrManager <= 2 ~ "Lessthan2",
                                                                  YearsWithCurrManager <= 4 ~ "2thru4",
                                                                  YearsWithCurrManager <= 6.9 ~ "4thru6",
                                                                  YearsWithCurrManager >= 7~ "7&above")))



attritionCompSet <-  mutate(attritionCompSet, YearsInCurrentRole.Group = as.factor(case_when(YearsInCurrentRole <=2 ~ "Lessthan2", 
                                                                 YearsInCurrentRole <= 3 ~ "Lessthan3",
                                                                 YearsInCurrentRole <= 4 ~ "Lessthan4",
                                                                 YearsInCurrentRole >4 ~ "5&above")))



attritionCompSet <- mutate(attritionCompSet, YearsAtCompany.Group = as.factor(case_when(YearsAtCompany <= 3 ~ "LessThan3",
                                                            YearsAtCompany <= 5 ~"3thru5",
                                                            YearsAtCompany <= 10 ~"5thru10",
                                                            YearsAtCompany > 10 ~"10&above")))



#chceck for gaps
which(is.na(attritionCompSet))


#create the other column
attritionCompSet$time.at.past.job <- ifelse(attritionCompSet$NumCompaniesWorked!=0, attritionCompSet$TotalWorkingYears-attritionCompSet$YearsAtCompany/attritionCompSet$NumCompaniesWorked,0)

library(BBmisc)
#found this column to not enhance the models unitil i normalized it
attritionCompSet$ntime.at.past.job <- normalize(attritionCompSet$time.at.past.job, method = "standardize", margin = 1L, on.constant ="quiet" )

detach("package:BBmisc")

#don't forget ID

attritionPredictionData <- select(attritionCompSet, c("ID","Age.Group", "DistanceFromHome", "MonthlyIncome.Group", "TotalWorkingYears", "OverTime", "YearsAtCompany", "StockOptionLevel", "JobRole", "JobLevel", "JobInvolvement", "Education", "EnvironmentSatisfaction", "WorkLifeBalance", "YearsInCurrentRole", "YearsAtCompany.Group",  "YearsInCurrentRole", "YearsWithCurrManager"))




colnames(attritionPredictionData)
colSums(is.na(attritionPredictionData)) # Triple check before we begin modeling


```




#~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
#                          Make Attrition Predictions
#~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~




```{r, Run the Model}


set.seed(7919) #big prime no wammies

    

library(e1071) #bring that library back in case randomForest masked it
library(caret)#bring that library back in case randomForest masked it
NB.Model2 <- naiveBayes(Attrition ~., data=dat, laplace = 1)
NB.Pred2 <- predict(NB.Model2, newdata = attritionPredictionData)

#save as backup object
Attrited <- NB.Pred2

Attrited = as.data.frame(Attrited)

#combine the predicitons into the data set
case2predictions <- cbind(attritionPredictionData, Attrited)

case2predictions <- select(case2predictions, -c("Age.Group", "DistanceFromHome", "MonthlyIncome.Group", "TotalWorkingYears", "OverTime", "YearsAtCompany", "StockOptionLevel", "JobRole", "JobLevel", "JobInvolvement", "Education", "EnvironmentSatisfaction", "WorkLifeBalance", "YearsInCurrentRole", "YearsAtCompany.Group",  "YearsInCurrentRole", "YearsWithCurrManager"))

#write it a csv in submission format
#write.csv(case2predictions,"Case2Predictions_LAZARUS_Attrition_NB_model.csv", row.names = FALSE)


#conver to a data frame 
#Attrition = as.data.frame(Attrition)
#SVMModel2 <- train(Attrition~., dat, method = 'svmRadial',trControl = trainControl(method = 'repeatedcv',number = 3))

#predict
#SVM.pred2 <- predict(SVMModel2,attritionPredictionData)


#saving the object as a back up
#Attrition <- SVM.pred2

#conver to a data frame 
#Attrition = as.data.frame(Attrition)

#combine the predicitons into the data set
#case2predictions <- cbind(attritionPredictionData,Attrition)

#scrub the data set so only ID and attritions predictions remain
#case2predictions <- select(case2predictions, -c("Age","DailyRate","DistanceFromHome" ,"Education","EnvironmentSatisfaction","HourlyRate" ,"JobInvolvement", "JobLevel" , "JobSatisfaction" ,"MonthlyIncome", "NumCompaniesWorked", "OverTime", "PercentSalaryHike","PerformanceRating" ,"RelationshipSatisfaction","StockOptionLevel", "TotalWorkingYears" , "TrainingTimesLastYear", "YearsAtCompany" ,"YearsInCurrentRole","YearsSinceLastPromotion" ,"time.at.past.job" ,"Age.Group", "MonthlyIncome.Group" ,"YearsAtCompany.Group"))
#write it a csv in submission format
#write.csv(case2predictions,"Case2Predictions_LAZARUS_Attrition_SVM_model.csv", row.names = FALSE)


```



#~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
#                        Begin Salary Modeling
#~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~



```{r, Salary objective: Predictions < 3000 RMSE}

library(ggplot2)
library(corrplot)

#creating a salary data this was an iteriative process between EDA, filtervarImp function and the models



saldat <- select(df, "MonthlyIncome", "Age", "YearsAtCompany", "YearsInCurrentRole", "TotalWorkingYears","JobLevel", "Attrition", "BusinessTravel","JobRole", "Department")

salints <- saldat[, 1:6]

salgroups <- saldat[, 10]

pairs(saldat, labels = colnames(salints), pch = 21, bg = rainbow(3)[salgroups], col=rainbow(3)[salgroups], main= "Salary Data", row1attop=TRUE, gap =1, cex.labels =NULL, font.labels=1)

M <- cor(salints)

corrplot(M, method = "square")

saldat %>% ggplot(mapping=aes(y=MonthlyIncome, x=Age,color=Age)) + geom_point(size=0.5, position=position_jitter(width = 0.001, height = 1)) + geom_smooth(method="lm",se=FALSE,size=1)+ labs(title="Correlation between Age and Monthly Income")

saldat %>% ggplot(mapping=aes(y=MonthlyIncome, x=JobLevel,color=Department)) + geom_point(size=0.5, position=position_jitter(width = 0.001, height = 1)) + geom_smooth(method="lm",se=FALSE,size=1)+ labs(title="Scatter plot Income by JobLevel")


saldat %>% ggplot(mapping=aes(y=MonthlyIncome, x=YearsAtCompany,color=Department)) + geom_point(size=0.5, position=position_jitter(width = 0.001, height = 1)) + geom_smooth(method="lm",se=TRUE,size=1)+ labs(title="Monthly Income Years at the Co.")

saldat %>% ggplot(mapping=aes(y=MonthlyIncome, x=TotalWorkingYears,color=JobLevel)) + geom_point(size=0.5, position=position_jitter(width = 0.001, height = 1)) + geom_smooth(method="lm",se=TRUE,size=1)+ labs(title="Monthly Income ")

saldat %>% ggplot(mapping=aes(y=MonthlyIncome, x=TotalWorkingYears,color=BusinessTravel)) + geom_point(size=0.5, position=position_jitter(width = 0.001, height = 1)) + geom_smooth(method="lm",se=TRUE,size=1)+ labs(title="Income by Total Working Years | business Travel")

```



#~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
#             Prepare data for Modeling  Train Test SPlit
#~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~



```{r, T/T/S}



set.seed(31) # get that prime number read, you know the drill.

sample_size = round(nrow(saldat)*.70) # setting what is 70%
index <- sample(seq_len(nrow(saldat)), size = sample_size)

training <- saldat[index, ]
test <- saldat[-index, ]

dim(df)
dim(training)
dim(test)

str(training)
summary(saldat)


```



#~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
#                    find important Var
#~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~


```{r, filter variable importance}
library(caret)
library(MASS)
roc_imp <- filterVarImp(x = training[-1], y = training$MonthlyIncome)
head(roc_imp)
roc_imp


```
#~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
#                      Bayesion Lasso Regression 
                                  or 
      the avg of posterior estimates of the regression coefficients 
#~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
```{r, BLASSO Baby }


library(caret)


BLASSO <- train(MonthlyIncome~., training, method = 'blassoAveraged')

predict(BLASSO$finalModel, type = 'coefficients')

coef(BLASSO$finalModel,unlist(BLASSO$bestTune))

lm(MonthlyIncome~., training)

#predict on Test Set
GLM.Pred <- predict(BLASSO, newdata =  test[-1])



qqplot
#printing summary
summary(GLM.Pred)
RMSE <- sqrt(mean((test$MonthlyIncome - GLM.Pred)^2))
RMSE
  #1022.88

postResample(pred = GLM.Pred, obs = test$MonthlyIncome)

hist(GLM.Pred, main = "Distribution of Predictions", xlab = "Salary Predictions")






```


#~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
#               Begin Salary Predictions Prep
#~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~


```{r, Import Competition data}

salaryCompset <- read.csv("https://raw.githubusercontent.com/JosephLazarus/CaseStudy2DDS_Work_Place_Attrition/main/the_data_folder/CaseStudy2CompSet%20No%20Salary.csv")

str(salaryCompset)
colnames(salaryCompset)
salaryCompset  <- rename(salaryCompset, ID = ï..ID) # weird character in fron of ID maybe so we don't forget and delete it accidentally. 
summary(salaryCompset)
dim(salaryCompset) # 300 X 35

which(is.na(salaryCompset)) # makes sure no funny business is going here

colSums(is.na(salaryCompset)) # still 0

salaryCompset <- select(salaryCompset, -c(Over18, EmployeeCount, StandardHours, EmployeeNumber))
dim(salaryCompset) #300 X 31

which(is.na(salaryCompset)) # makes sure no funny business is going here
colSums(is.na(salaryCompset)) # still 0


#convert interger vars to factors
var_facs <- c("EducationField","MaritalStatus","BusinessTravel","JobRole", "Department", "OverTime", "Gender")
salaryCompset[,var_facs] <- lapply(salaryCompset[,var_facs] , factor, ordered = FALSE)

salaryCompset$iJobRole <- as.integer(salaryCompset$JobRole)
salaryCompset$iDepartment <- as.integer(salaryCompset$Department)
salaryCompset$iMaritalStatus <- as.integer(salaryCompset$MaritalStatus)
salaryCompset$iBusinessTravel <- as.integer(salaryCompset$BusinessTravel)
salaryCompset$iEducation <- as.integer(salaryCompset$Education)

str(salaryCompset)
colSums(is.na(salaryCompset))

salaryCompset$time.at.past.job <- ifelse(salaryCompset$NumCompaniesWorked!=0, salaryCompset$TotalWorkingYears-salaryCompset$YearsAtCompany/salaryCompset$NumCompaniesWorked,0)

library(BBmisc)

salaryCompset$ntime.at.past.job <- normalize(salaryCompset$time.at.past.job,  method = "standardize", on.constant = "quiet")

detach("package:BBmisc")

colnames(salaryCompset)


salaryPredictionData <- select(salaryCompset, c("ID", "Age", "Attrition", "BusinessTravel", "YearsAtCompany", "YearsInCurrentRole", "TotalWorkingYears", "JobLevel", "JobRole", "Department"))
colnames(salaryPredictionData)
summary(salaryPredictionData)
colSums(is.na(salaryPredictionData))

```



#~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
#                      Make Salary Predictions
#~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~



```{r,Salary Predictions}

set.seed(3967) # big prime no wammies

predictSalary <- train(MonthlyIncome ~ ., data= saldat, method = 'blassoAveraged')

salaryPredictions <- predict(predictSalary, salaryPredictionData)


salary <- salaryPredictions

salary = as.data.frame(salary)

case2SalaryPredictions <-cbind(salaryPredictionData, salary)

case2SalaryPredictions <- select(case2SalaryPredictions, -c("Age", "Attrition", "BusinessTravel", "YearsAtCompany", "YearsInCurrentRole", "TotalWorkingYears", "JobLevel", "JobRole", "Department"))

#write.csv(case2SalaryPredictions, "Case2PredictionsLAZARUSSalary.csv", row.names = FALSE)


```

```{r}

sessionInfo()

```